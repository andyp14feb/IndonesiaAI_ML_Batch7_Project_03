{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc656645",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7febaa",
   "metadata": {},
   "source": [
    "## Data Definition\n",
    "please refer to :\n",
    "- dataDefinision.md\n",
    "- data_description.txt\n",
    "- CategoricalEncodingnyaPakaiApa.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e284c4d",
   "metadata": {},
   "source": [
    "## Data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the data description file.\n",
    "\n",
    "- **SalePrice**Â - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- **MSSubClass**: The building class\n",
    "- **MSZoning**: The general zoning classification\n",
    "- **LotFrontage**: Linear feet of street connected to property\n",
    "- **LotArea**: Lot size in square feet\n",
    "- **Street**: Type of road access\n",
    "- **Alley**: Type of alley access\n",
    "- **LotShape**: General shape of property\n",
    "- **LandContour**: Flatness of the property\n",
    "- **Utilities**: Type of utilities available\n",
    "- **LotConfig**: Lot configuration\n",
    "- **LandSlope**: Slope of property\n",
    "- **Neighborhood**: Physical locations within Ames city limits\n",
    "- **Condition1**: Proximity to main road or railroad\n",
    "- **Condition2**: Proximity to main road or railroad (if a second is present)\n",
    "- **BldgType**: Type of dwelling\n",
    "- **HouseStyle**: Style of dwelling\n",
    "- **OverallQual**: Overall material and finish quality\n",
    "- **OverallCond**: Overall condition rating\n",
    "- **YearBuilt**: Original construction date\n",
    "- **YearRemodAdd**: Remodel date\n",
    "- **RoofStyle**: Type of roof\n",
    "- **RoofMatl**: Roof material\n",
    "- **Exterior1st**: Exterior covering on house\n",
    "- **Exterior2nd**: Exterior covering on house (if more than one material)\n",
    "- **MasVnrType**: Masonry veneer type\n",
    "- **MasVnrArea**: Masonry veneer area in square feet\n",
    "- **ExterQual**: Exterior material quality\n",
    "- **ExterCond**: Present condition of the material on the exterior\n",
    "- **Foundation**: Type of foundation\n",
    "- **BsmtQual**: Height of the basement\n",
    "- **BsmtCond**: General condition of the basement\n",
    "- **BsmtExposure**: Walkout or garden level basement walls\n",
    "- **BsmtFinType1**: Quality of basement finished area\n",
    "- **BsmtFinSF1**: Type 1 finished square feet\n",
    "- **BsmtFinType2**: Quality of second finished area (if present)\n",
    "- **BsmtFinSF2**: Type 2 finished square feet\n",
    "- **BsmtUnfSF**: Unfinished square feet of basement area\n",
    "- **TotalBsmtSF**: Total square feet of basement area\n",
    "- **Heating**: Type of heating\n",
    "- **HeatingQC**: Heating quality and condition\n",
    "- **CentralAir**: Central air conditioning\n",
    "- **Electrical**: Electrical system\n",
    "- **1stFlrSF**: First Floor square feet\n",
    "- **2ndFlrSF**: Second floor square feet\n",
    "- **LowQualFinSF**: Low quality finished square feet (all floors)\n",
    "- **GrLivArea**: Above grade (ground) living area square feet\n",
    "- **BsmtFullBath**: Basement full bathrooms\n",
    "- **BsmtHalfBath**: Basement half bathrooms\n",
    "- **FullBath**: Full bathrooms above grade\n",
    "- **HalfBath**: Half baths above grade\n",
    "- **Bedroom**: Number of bedrooms above basement level\n",
    "- **Kitchen**: Number of kitchens\n",
    "- **KitchenQual**: Kitchen quality\n",
    "- **TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)\n",
    "- **Functional**: Home functionality rating\n",
    "- **Fireplaces**: Number of fireplaces\n",
    "- **FireplaceQu**: Fireplace quality\n",
    "- **GarageType**: Garage location\n",
    "- **GarageYrBlt**: Year garage was built\n",
    "- **GarageFinish**: Interior finish of the garage\n",
    "- **GarageCars**: Size of garage in car capacity\n",
    "- **GarageArea**: Size of garage in square feet\n",
    "- **GarageQual**: Garage quality\n",
    "- **GarageCond**: Garage condition\n",
    "- **PavedDrive**: Paved driveway\n",
    "- **WoodDeckSF**: Wood deck area in square feet\n",
    "- **OpenPorchSF**: Open porch area in square feet\n",
    "- **EnclosedPorch**: Enclosed porch area in square feet\n",
    "- **3SsnPorch**: Three season porch area in square feet\n",
    "- **ScreenPorch**: Screen porch area in square feet\n",
    "- **PoolArea**: Pool area in square feet\n",
    "- **PoolQC**: Pool quality\n",
    "- **Fence**: Fence quality\n",
    "- **MiscFeature**: Miscellaneous feature not covered in other categories\n",
    "- **MiscVal**: $Value of miscellaneous feature\n",
    "- **MoSold**: Month Sold\n",
    "- **YrSold**: Year Sold\n",
    "- **SaleType**: Type of sale\n",
    "- **SaleCondition**: Condition of sale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be935496",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ GENERAL ============================\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================ PLOTTING ============================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================ PREPROCESSING & ENCODING ============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# ============================ MODELLING ============================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ============================ EVALUATION ============================\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ============================ HYPERPARAMETER TUNING ============================\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577de37",
   "metadata": {},
   "source": [
    "# Function Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e2921",
   "metadata": {},
   "source": [
    "#### get_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_now_string(style = 1):\n",
    "    # Dapetin waktu skrg\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Cek style yang diminta\n",
    "    if style == 1:\n",
    "        # Format jadi format yang diminta 'yyyy-mm-dd_ddd_hhmm'\n",
    "        formatted_datetime = current_datetime.strftime('%Y-%m-%d_%a_%H%M_%S')\n",
    "    elif style == 2:\n",
    "        # Format ke 'yyyy-mm-dd_hhmm'\n",
    "        formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H%M_%S')\n",
    "    elif style == 3:\n",
    "        # Format jadi format yang diminta 'yyyy-mm-dd_ddd_hhmm'\n",
    "        formatted_datetime = current_datetime.strftime('%Y-%m-%d_%a_%H%M')\n",
    "    elif style == 4:\n",
    "        # Format ke 'yyyy-mm-dd_hhmm'\n",
    "        formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H%M')\n",
    "    else:\n",
    "        # Default format 'yyyy-mm-dd_ddd_hhmm'\n",
    "        formatted_datetime = current_datetime.strftime('%Y-%m-%d_%a_%H%M_%S')\n",
    "    \n",
    "    return formatted_datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef5b2a",
   "metadata": {},
   "source": [
    "#### normalize_column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6708cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column_names(df):\n",
    "    # Normalisasi setiap kolom dalam dataframe agar enak dibaca\n",
    "    df.columns = [\n",
    "        # Menambahkan prefix berdasarkan tipe data kolom\n",
    "        ('num_' if pd.api.types.is_numeric_dtype(df[col]) else 'txt_') +\n",
    "        re.sub(r'[^a-zA-Z0-9\\s]', '_', col)  # Ganti simbol dengan '_'\n",
    "        .replace(' ', '_')  # Ganti spasi dengan '_'\n",
    "        .lower()  # Ubah ke lowercase\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce0b15",
   "metadata": {},
   "source": [
    "#### printMissingInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMissingInfo(df):\n",
    "    missing_info =df.isnull().sum()\n",
    "    missing_info = missing_info[missing_info>0]\n",
    "    missing_info= missing_info.sort_values(ascending=False)\n",
    "    missing_info_percentage = (missing_info / len(df)) * 100\n",
    "\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing Count': missing_info,\n",
    "        'Missing Percentage': missing_info_percentage\n",
    "    })\n",
    "\n",
    "    return missing_summary.sort_values(by='Missing Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b8a3c",
   "metadata": {},
   "source": [
    "#### one_hot_encode_columns_general()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e849b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_columns_general(df, columns):\n",
    "    df_encoded = pd.get_dummies(df[columns], prefix=columns)\n",
    "    df = df.drop(columns=columns)\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20f035",
   "metadata": {},
   "source": [
    "#### target_encode_columns_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd944a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_columns_general(df, target_col, columns):\n",
    "    te = TargetEncoder(cols=columns)\n",
    "    encoded = te.fit_transform(df[columns], df[target_col])\n",
    "    \n",
    "    df_transformed = df.drop(columns=columns)\n",
    "    df_transformed = pd.concat([df_transformed, encoded], axis=1)\n",
    "    \n",
    "    return df_transformed, te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e76508",
   "metadata": {},
   "source": [
    "#### save_model(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11444f69",
   "metadata": {},
   "source": [
    "#### load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    print(f\"Model loaded from {filename}\")\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bb98e",
   "metadata": {},
   "source": [
    "#### show_corrMap(pandas_df, savedImageName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb380f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_corrMap(pandas_df, savedImageName):\n",
    "    df_corr = pandas_df.corr(numeric_only=True)\n",
    "    # --- create upper-triangle mask to avoid duplicates (optional) ---\n",
    "    mask = np.triu(np.ones_like(df_corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(11, 9))\n",
    "    sns.heatmap(\n",
    "        df_corr,\n",
    "        # mask=mask,              # comment this line if you want full matrix\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        vmin=-1, vmax=1,\n",
    "        annot=True,             # <-- numbers on cells\n",
    "        fmt=\".2f\",              # 2-decimal format\n",
    "        annot_kws={\"size\": 8},  # font size for numbers\n",
    "        linewidths=.5,\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": .8}\n",
    "    )\n",
    "    plt.title('Feature Correlation Matrix (annotated)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savedImageName, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ea9fd",
   "metadata": {},
   "source": [
    "#### remove_highly_correlated_features(df, target_column, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f96025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, target_column, threshold=0.7):\n",
    "\n",
    "    dfx = df.copy() \n",
    "    removed = []\n",
    "\n",
    "    while True:\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = dfx.corr()\n",
    "\n",
    "        # make absolute value then sort highest to lowest\n",
    "        high_corr_pairs = (\n",
    "            corr_matrix\n",
    "            .abs() \n",
    "            .where(~np.eye(len(corr_matrix), dtype=bool))  # mask diagonal\n",
    "            .stack() # dataframe 2D jadi 1D (semacam di pivot jadi panjang ke bawah feature1, feature2, value)\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "\n",
    "        # Filter corr that above threshold\n",
    "        high_corr_pairs = high_corr_pairs[high_corr_pairs > threshold]\n",
    "        if high_corr_pairs.empty:\n",
    "            break  #selesai\n",
    "\n",
    "        # Pick the highest correlation pair\n",
    "        feature1, feature2 = high_corr_pairs.index[0]\n",
    "\n",
    "        # Compare correlation to target\n",
    "        corr_to_target = corr_matrix[target_column]\n",
    "        corr1 = abs(corr_to_target.get(feature1, 0))\n",
    "        corr2 = abs(corr_to_target.get(feature2, 0))\n",
    "        # Remove the weaker one\n",
    "        if corr1 < corr2:\n",
    "            to_remove = feature1\n",
    "        else:\n",
    "            to_remove = feature2\n",
    "        print(f'will remove {to_remove}')\n",
    "        dfx.drop(columns=to_remove, inplace=True)\n",
    "        \n",
    "        removed.append(to_remove)\n",
    "\n",
    "    return dfx, removed   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8521b",
   "metadata": {},
   "source": [
    "#### calculate_vif_v2(df, target_column, vif_threshold=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif_v2(df, target_column, vif_threshold=5.0):\n",
    "   \n",
    "    print('entering calculate_vif()')\n",
    "    # Work on a copy of the feature set (drop the target column)\n",
    "    X = df.drop(columns=[target_column]).copy()\n",
    "    dropped_features = []\n",
    "\n",
    "    while True:\n",
    "        # Calculate VIF\n",
    "        print('Calculate VIF')\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data['feature'] = X.columns\n",
    "        vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "        # Check the highest VIF\n",
    "        max_vif = vif_data['VIF'].max()\n",
    "        if max_vif > vif_threshold:\n",
    "            feature_to_drop = vif_data.sort_values('VIF', ascending=False).iloc[0]['feature']\n",
    "            print(f\"ðŸ“‰ Dropping '{feature_to_drop}' with VIF = {max_vif:.2f}\")\n",
    "            X.drop(columns=[feature_to_drop], inplace=True)\n",
    "            dropped_features.append(feature_to_drop)\n",
    "        else:\n",
    "            print(\"âœ… All features now have VIF below threshold.\")\n",
    "            break\n",
    "\n",
    "    # Final VIF report\n",
    "    final_vif = pd.DataFrame()\n",
    "    final_vif['feature'] = X.columns\n",
    "    final_vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return pd.concat([X, df[[target_column]]], axis=1), dropped_features, final_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6529c17",
   "metadata": {},
   "source": [
    "#### calculate_mape(y_actual,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(y_actual, y_pred):\n",
    "    y_actual = np.array(y_actual)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    absolute_percentage_error = np.abs((y_actual - y_pred) / y_actual) * 100\n",
    "\n",
    "    mape = np.mean(absolute_percentage_error)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289a1ac",
   "metadata": {},
   "source": [
    "# EDA & Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717eb5ee",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a81fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample data\n",
    "file_path = './data/train.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_original = df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee6440",
   "metadata": {},
   "source": [
    "## Feature Name Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_normalize = normalize_column_names(df_original.copy(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4223bcf",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**num_mssubclass** ,though the content is number, but I think it is only label (based on data description)\n",
    "so it should be handled as text / criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_normalize=df_01_normalize.rename(columns={'num_mssubclass': 'txt_mssubclass'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_01_normalize.copy(deep=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e39a8",
   "metadata": {},
   "source": [
    "## mini EDA summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac66e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat ringkasan EDA\n",
    "eda_summary = {\n",
    "    \"Dataset Shape\": df.shape,\n",
    "    \"Column Names\": df.columns.tolist(),\n",
    "    \n",
    "    # Menampilkan hanya kolom dengan missing values dan jumlah missing values-nya\n",
    "    \"Missing Values\": df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False).apply(lambda x: f\"{x}\"),\n",
    "    \n",
    "    \"Numerical Features\": df.select_dtypes(include=['number']).columns.tolist(),\n",
    "    \"Categorical Features\": df.select_dtypes(include=['object']).columns.tolist(),\n",
    "    \"Sample Data\": df.head(15)\n",
    "}\n",
    "\n",
    "# Menyiapkan direktori dan nama file output\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Membuat folder jika belum ada\n",
    "output_file = os.path.join(output_dir, f'{get_now_string()}_summary.txt')\n",
    "\n",
    "# Menulis ringkasan EDA ke dalam file teks\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Exploratory Data Analysis Summary:\\n\\n\")\n",
    "    \n",
    "    # Menyusun data ringkasan dan menulis ke file\n",
    "    for key, value in eda_summary.items():\n",
    "        f.write(f\"{key}:\\n\")\n",
    "        \n",
    "        # Mengubah list atau DataFrame menjadi string\n",
    "        if isinstance(value, (list, pd.Series)):\n",
    "            value = '\\n'.join(map(str, value))  # Menyusun elemen list menjadi string\n",
    "        elif isinstance(value, pd.DataFrame):\n",
    "            value = value.to_string(index=False)  # Mengubah DataFrame menjadi string tanpa index\n",
    "\n",
    "        f.write(f\"{value}\\n\\n\")\n",
    "\n",
    "# Menampilkan pesan bahwa ringkasan telah ditulis\n",
    "print(f\"Summary ditulis ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c659bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'num_saleprice'\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[feature], kde=True, color='blue', bins=30)\n",
    "plt.title(f'Distribution of {feature}')\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = df[feature].skew()\n",
    "\n",
    "# Display skewness\n",
    "print(f'Skewness of {feature}: {skewness}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b545a",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96e98758",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "mostly are txt_ (categorical columns) that has missing values<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b2471",
   "metadata": {},
   "source": [
    "### txt_poolqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29327cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_poolqc\n",
    "# =============================\n",
    "\n",
    "print(df['txt_poolqc'].unique())\n",
    "\n",
    "ygNull = df['txt_poolqc'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_poolarea', 'txt_poolqc']]\n",
    "print(df_result)\n",
    "\n",
    "ygKosong = df_result['num_poolarea'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_poolqc\n",
    "# =============================\n",
    "df.loc[df['num_poolarea'] == 0, 'txt_poolqc'] = \"NA\"\n",
    "\n",
    "print(df['txt_poolqc'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7e854",
   "metadata": {},
   "source": [
    "### txt_miscfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f563a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_miscfeature     \n",
    "# =============================\n",
    "df.loc[df['txt_miscfeature'].isnull() , 'txt_miscfeature'] = \"NA\"\n",
    "\n",
    "print(df['txt_miscfeature'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b47d6",
   "metadata": {},
   "source": [
    "### txt_alley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_alley     \n",
    "# =============================\n",
    "print(df['txt_alley'].unique())\n",
    "\n",
    "df.loc[df['txt_alley'].isnull() , 'txt_alley'] = \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d25dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde91122",
   "metadata": {},
   "source": [
    "### Cek kolom txt_fence     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2399f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_fence     \n",
    "# =============================\n",
    "print(df['txt_fence'].unique())\n",
    "\n",
    "df.loc[df['txt_fence'].isnull() , 'txt_fence'] = \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a956a9",
   "metadata": {},
   "source": [
    "### txt_fireplacequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14947811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_fireplacequ\n",
    "# =============================\n",
    "\n",
    "print(df['txt_fireplacequ'].unique())\n",
    "\n",
    "ygNull = df['txt_fireplacequ'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_fireplaces', 'txt_fireplacequ']]\n",
    "print(df_result)\n",
    "\n",
    "ygKosong = df_result['num_fireplaces'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_fireplacequ\n",
    "# =============================\n",
    "print(df['txt_fireplacequ'].unique())\n",
    "\n",
    "df.loc[df['num_fireplaces'] == 0, 'txt_fireplacequ'] = \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e46ec6",
   "metadata": {},
   "source": [
    "### txt_garagetype , txt_garagefinish,  txt_garagequal,txt_garagecond,num_garageyrblt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d944c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_garagetype\n",
    "# =============================\n",
    "\n",
    "print(df['txt_garagetype'].unique())\n",
    "\n",
    "ygNull = df['txt_garagetype'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_garageyrblt', 'txt_garagetype','txt_garagefinish','txt_garagequal','txt_garagecond']]\n",
    "print(df_result)\n",
    "\n",
    "ygKosong = df_result['num_garageyrblt'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_garagetype\n",
    "# =============================\n",
    "print(df['txt_garagetype'].unique())\n",
    "\n",
    "df.loc[df['num_garageyrblt'].isnull(), 'txt_garagetype'] = \"NA\"\n",
    "df.loc[df['num_garageyrblt'].isnull(), 'txt_garagefinish'] = \"NA\"\n",
    "df.loc[df['num_garageyrblt'].isnull(), 'txt_garagequal'] = \"NA\"\n",
    "df.loc[df['num_garageyrblt'].isnull(), 'txt_garagecond'] = \"NA\"\n",
    "df.loc[df['num_garageyrblt'].isnull(), 'num_garageyrblt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0628737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['num_garageyrblt'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d70d5f",
   "metadata": {},
   "source": [
    "### txt_bsmtexposure,txt_bsmtfintype2,txt_bsmtqual,txt_bsmtcond,txt_bsmtfintype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtexposure\n",
    "# =============================\n",
    "\n",
    "# print(df['num_totalbsmtsf'].unique())\n",
    "# print(df['txt_bsmtexposure'].unique())\n",
    "# print(df['txt_bsmtfintype2'].unique())\n",
    "# print(df['txt_bsmtqual'].unique())\n",
    "# print(df['txt_bsmtcond'].unique())\n",
    "# print(df['txt_bsmtfintype1'].unique())\n",
    "\n",
    "ygNull = df['txt_bsmtexposure'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_totalbsmtsf', 'txt_bsmtexposure','txt_bsmtfintype2','txt_bsmtqual','txt_bsmtcond','txt_bsmtfintype1']]\n",
    "print(df_result)\n",
    "\n",
    "ygKosong = df_result['num_totalbsmtsf'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtexposure\n",
    "# =============================\n",
    "print(df['txt_bsmtexposure'].unique())\n",
    "df.loc[df['num_totalbsmtsf']==0, 'txt_bsmtexposure'] = \"NA\"\n",
    "print(df['txt_bsmtexposure'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtfintype2\n",
    "# =============================\n",
    "print(df['txt_bsmtfintype2'].unique())\n",
    "df.loc[df['num_totalbsmtsf']==0, 'txt_bsmtfintype2'] = \"NA\"\n",
    "print(df['txt_bsmtfintype2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5911704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtqual\n",
    "# =============================\n",
    "print(df['txt_bsmtqual'].unique())\n",
    "df.loc[df['num_totalbsmtsf']==0, 'txt_bsmtqual'] = \"NA\"\n",
    "print(df['txt_bsmtqual'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtcond\n",
    "# =============================\n",
    "print(df['txt_bsmtcond'].unique())\n",
    "df.loc[df['num_totalbsmtsf']==0, 'txt_bsmtcond'] = \"NA\"\n",
    "print(df['txt_bsmtcond'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7152b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtfintype1\n",
    "# =============================\n",
    "print(df['txt_bsmtfintype1'].unique())\n",
    "df.loc[df['num_totalbsmtsf']==0, 'txt_bsmtfintype1'] = \"NA\"\n",
    "print(df['txt_bsmtfintype1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtexposure\n",
    "# =============================\n",
    "\n",
    "print(df['txt_bsmtexposure'].unique())\n",
    "print(df['txt_bsmtfintype2'].unique())\n",
    "\n",
    "print('---------------------------------------')\n",
    "\n",
    "ygNull = df['txt_bsmtexposure'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_totalbsmtsf', 'txt_bsmtexposure','txt_bsmtfintype2']]\n",
    "print(df_result)\n",
    "\n",
    "print('---------------------------------------')\n",
    "\n",
    "ygNull = df['txt_bsmtfintype2'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_totalbsmtsf', 'txt_bsmtexposure','txt_bsmtfintype2']]\n",
    "print(df_result)\n",
    "\n",
    "print('---------------------------------------')\n",
    "\n",
    "ygKosong = df_result['num_totalbsmtsf'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtexposure\n",
    "# =============================\n",
    "print(df['txt_bsmtexposure'].unique())\n",
    "df.loc[df['txt_bsmtexposure'].isnull(), 'txt_bsmtexposure'] = \"NA\"\n",
    "print(df['txt_bsmtexposure'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30751e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_bsmtfintype2\n",
    "# =============================\n",
    "print(df['txt_bsmtfintype2'].unique())\n",
    "df.loc[df['txt_bsmtfintype2'].isnull(), 'txt_bsmtfintype2'] = \"NA\"\n",
    "print(df['txt_bsmtfintype2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667cd69",
   "metadata": {},
   "source": [
    "### txt_masvnrtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_masvnrtype\n",
    "# =============================\n",
    "\n",
    "print(df['txt_masvnrtype'].unique())\n",
    "\n",
    "ygNull = df['txt_masvnrtype'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result = df_filtered[['num_masvnrarea', 'txt_masvnrtype']]\n",
    "print(df_result)\n",
    "\n",
    "ygKosong = df_result['num_masvnrarea'] == 0\n",
    "df_result2 = df_result[ygKosong]\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_masvnrtype\n",
    "# =============================\n",
    "print(df['txt_masvnrtype'].unique())\n",
    "df.loc[df['num_masvnrarea'].isnull(), 'txt_masvnrtype'] = \"None\"\n",
    "print(df['txt_masvnrtype'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_masvnrtype\n",
    "# =============================\n",
    "# print(df['num_masvnrarea'].unique())\n",
    "df.loc[df['num_masvnrarea'].isnull(), 'num_masvnrarea'] = 0\n",
    "# print(df['num_masvnrarea'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8445ff9",
   "metadata": {},
   "source": [
    "### txt_electrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db93b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_electrical\n",
    "# =============================\n",
    "\n",
    "print(df['txt_electrical'].unique())\n",
    "\n",
    "ygNull = df['txt_electrical'].isnull()\n",
    "df_filtered = df[ygNull]\n",
    "df_result =  df_filtered[['txt_electrical','txt_heating','txt_utilities']]\n",
    "print(df_result)\n",
    "\n",
    "electrical_counts_groupby = df[df['txt_utilities'] == 'AllPub'].groupby('txt_electrical').size()\n",
    "print(electrical_counts_groupby)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Cek kolom txt_electrical\n",
    "# =============================\n",
    "print(df['txt_electrical'].unique())\n",
    "df.loc[df['txt_electrical'].isnull(), 'txt_electrical'] = 'FuseA'\n",
    "print(df['txt_electrical'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593943f4",
   "metadata": {},
   "source": [
    "### num_lotfrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba49ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['num_saleprice']['num_lotfrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5130814",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'num_lotfrontage'\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[feature], kde=True, color='blue', bins=30)\n",
    "plt.title(f'Distribution of {feature}')\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = df[feature].skew()\n",
    "\n",
    "# Display skewness\n",
    "print(f'Skewness of {feature}: {skewness}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36bf36d9",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for 'num_lotfrontage' i got :\n",
    "correlation to target : 0.35179909657067737\n",
    "missing values : 259 (17.73972602739726%)\n",
    "right skew graph\n",
    "\n",
    "lets chek again with the neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23545bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lotfrontage_median_by_txt_neighborhood = df.groupby('txt_neighborhood')['num_lotfrontage'].median().reset_index()\n",
    "print(num_lotfrontage_median_by_txt_neighborhood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lotfrontage_median_by_txt_neighborhood.rename(columns={'num_lotfrontage': 'num_medianlotfrontage_by_neighborhood'}, inplace=True)\n",
    "print(num_lotfrontage_median_by_txt_neighborhood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df,\n",
    "    num_lotfrontage_median_by_txt_neighborhood,\n",
    "    on='txt_neighborhood',  # Join key\n",
    "    how='left'          # Keep all rows from df\n",
    ")\n",
    "print(df_merged[df_merged['num_lotfrontage'].isnull()][['txt_neighborhood', 'num_lotfrontage', 'num_medianlotfrontage_by_neighborhood']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['num_lotfrontage2'] = np.where(df_merged['num_lotfrontage'].notnull(), \n",
    "                                          df_merged['num_lotfrontage'], \n",
    "                                          df_merged['num_medianlotfrontage_by_neighborhood'])\n",
    "df_merged.drop(columns=['num_lotfrontage', 'num_medianlotfrontage_by_neighborhood'], inplace=True)\n",
    "df_merged.rename(columns={'num_lotfrontage2': 'num_lotfrontage'}, inplace=True)\n",
    "df=df_merged.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingInfo(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_columns = [col for col in df.columns if col.startswith('txt_')]\n",
    "unique_values = {}\n",
    "for col in txt_columns:\n",
    "    # Get the unique values for the current column and add it to the dictionary\n",
    "    unique_values[col] = df[col].nunique()\n",
    "\n",
    "print(unique_values)\n",
    "\n",
    "listnya=list(unique_values.items())\n",
    "unique_values_df=pd.DataFrame(listnya, columns=['Column', 'UniqueValueCount'])\n",
    "\n",
    "print(unique_values_df)\n",
    "unique_values_df.to_csv(f'./output/{get_now_string()}_unique_values_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f81aa",
   "metadata": {},
   "source": [
    "based on checking (see : CategoricalEncodingnyaPakaiApa.xlsx)\n",
    "<br>\n",
    "######################\n",
    "<br>\n",
    "**no need encoding** <br>\n",
    "'txt_overallqual', 'txt_overallcond',\n",
    "\n",
    "**OHE** <br>\n",
    "'txt_street','txt_alley','txt_landslope','txt_centralair','txt_paveddrive',\n",
    "\n",
    "**Target Encoding** <br>\n",
    "'txt_mssubclass','txt_mszoning','txt_lotshape','txt_landcontour','txt_utilities',<br>\n",
    "'txt_lotconfig','txt_neighborhood','txt_condition1','txt_condition2','txt_bldgtype',<br>\n",
    "'txt_housestyle','txt_roofstyle','txt_roofmatl','txt_exterior1st','txt_exterior2nd',<br>\n",
    "'txt_masvnrtype','txt_exterqual','txt_extercond','txt_foundation','txt_bsmtqual',<br>\n",
    "'txt_bsmtcond','txt_bsmtexposure','txt_bsmtfintype1','txt_bsmtfintype2','txt_heating',<br>\n",
    "'txt_heatingqc','txt_electrical','txt_kitchenqual','txt_functional','txt_fireplacequ',<br>\n",
    "'txt_garagetype','txt_garagefinish','txt_garagequal','txt_garagecond','txt_poolqc',<br>\n",
    "'txt_fence','txt_miscfeature','txt_saletype','txt_salecondition',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d00f4",
   "metadata": {},
   "source": [
    "untuk :\n",
    "- 'txt_mssubclass',\n",
    "- 'txt_mszoning',\n",
    "- 'txt_utilities',\n",
    "- 'txt_condition2',\n",
    "- 'txt_exterior1st',\n",
    "- 'txt_exterior2nd',\n",
    "- 'txt_masvnrtype',\n",
    "- 'txt_exterqual',\n",
    "- 'txt_bsmtqual',\n",
    "- 'txt_bsmtcond',\n",
    "- 'txt_kitchenqual',\n",
    "- 'txt_functional',\n",
    "- 'txt_poolqc',\n",
    "- 'txt_miscfeature',\n",
    "- 'txt_saletype',\n",
    "<br>\n",
    "\n",
    "jumlah unique value pada data is less than what is listed in data description / definition .<br>\n",
    "but for the simplicity of this project (and we don't have new data that might have <br>\n",
    "categorical values other than that already listed in the curren data ), <br>\n",
    "i decided not to include any categorical value that is listed in the data description / definition but<br>\n",
    "not listed in the training/test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b339a49",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encode_columns_general(df, ['txt_street','txt_alley','txt_landslope','txt_centralair','txt_paveddrive'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f9a23",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"num_saleprice\", axis=1)\n",
    "y = df[\"num_saleprice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "#create backup as usual \n",
    "df_train.to_csv(f'./output/{get_now_string()}_df_train.csv', index=False)\n",
    "df_test.to_csv(f'./output/{get_now_string()}_df_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_train.shape={df_train.shape}')\n",
    "print(f'df_test.shape={df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74935f0",
   "metadata": {},
   "source": [
    "## Target Encoding after Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, encodernya = target_encode_columns_general(df_train, target_col='num_saleprice'\n",
    "                                               , columns=['txt_mssubclass','txt_mszoning','txt_lotshape','txt_landcontour','txt_utilities','txt_lotconfig',\n",
    "                                                          'txt_neighborhood','txt_condition1','txt_condition2','txt_bldgtype','txt_housestyle',\n",
    "                                                          'txt_roofstyle','txt_roofmatl','txt_exterior1st','txt_exterior2nd','txt_masvnrtype',\n",
    "                                                          'txt_exterqual','txt_extercond','txt_foundation','txt_bsmtqual','txt_bsmtcond',\n",
    "                                                          'txt_bsmtexposure','txt_bsmtfintype1','txt_bsmtfintype2','txt_heating','txt_heatingqc',\n",
    "                                                          'txt_electrical','txt_kitchenqual','txt_functional','txt_fireplacequ','txt_garagetype',\n",
    "                                                          'txt_garagefinish','txt_garagequal','txt_garagecond','txt_poolqc','txt_fence',\n",
    "                                                          'txt_miscfeature','txt_saletype','txt_salecondition'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_full = df_test.copy()\n",
    "\n",
    "#endcoder only process the feature that need to be target encoded so does the encoding result\n",
    "#so we need to copy the full df , DROP the features being encoded, and ADD the encoded result back\n",
    "\n",
    "df_transformed_cols = encodernya.transform(df_test[['txt_mssubclass','txt_mszoning','txt_lotshape','txt_landcontour','txt_utilities','txt_lotconfig',\n",
    "                                                          'txt_neighborhood','txt_condition1','txt_condition2','txt_bldgtype','txt_housestyle',\n",
    "                                                          'txt_roofstyle','txt_roofmatl','txt_exterior1st','txt_exterior2nd','txt_masvnrtype',\n",
    "                                                          'txt_exterqual','txt_extercond','txt_foundation','txt_bsmtqual','txt_bsmtcond',\n",
    "                                                          'txt_bsmtexposure','txt_bsmtfintype1','txt_bsmtfintype2','txt_heating','txt_heatingqc',\n",
    "                                                          'txt_electrical','txt_kitchenqual','txt_functional','txt_fireplacequ','txt_garagetype',\n",
    "                                                          'txt_garagefinish','txt_garagequal','txt_garagecond','txt_poolqc','txt_fence',\n",
    "                                                          'txt_miscfeature','txt_saletype','txt_salecondition']])\n",
    "\n",
    "\n",
    "df_test_full = df_test_full.drop(columns=['txt_mssubclass','txt_mszoning','txt_lotshape','txt_landcontour','txt_utilities','txt_lotconfig',\n",
    "                                                          'txt_neighborhood','txt_condition1','txt_condition2','txt_bldgtype','txt_housestyle',\n",
    "                                                          'txt_roofstyle','txt_roofmatl','txt_exterior1st','txt_exterior2nd','txt_masvnrtype',\n",
    "                                                          'txt_exterqual','txt_extercond','txt_foundation','txt_bsmtqual','txt_bsmtcond',\n",
    "                                                          'txt_bsmtexposure','txt_bsmtfintype1','txt_bsmtfintype2','txt_heating','txt_heatingqc',\n",
    "                                                          'txt_electrical','txt_kitchenqual','txt_functional','txt_fireplacequ','txt_garagetype',\n",
    "                                                          'txt_garagefinish','txt_garagequal','txt_garagecond','txt_poolqc','txt_fence',\n",
    "                                                          'txt_miscfeature','txt_saletype','txt_salecondition'])\n",
    "\n",
    "df_test = pd.concat([df_test_full, df_transformed_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_train.shape={df_train.shape}')\n",
    "print(f'df_test.shape={df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290933b3",
   "metadata": {},
   "source": [
    "## Steps summary for data prepreprocessing:\n",
    "- normalize column names\n",
    "- handle missing values\n",
    "- doing OHE before splitting\n",
    "- doing Target Encoding after splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f61f6",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8b71d",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c6ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bad239",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([{\n",
    "    \"Model\": '-',\n",
    "    \"RMSE\": 0,\n",
    "    \"MAE\": 0,\n",
    "    \"MAPE\": 0,    \n",
    "    \"R2\": 0,\n",
    "    \"Model File\": '',\n",
    "    \"df_train\": '',\n",
    "    \"df_test\":'',\n",
    "    \"Scaler File\":''\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48586aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['num_saleprice'])\n",
    "y_train = df_train['num_saleprice']\n",
    "X_test = df_test.drop(columns=['num_saleprice'])\n",
    "y_test = df_test['num_saleprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fe77b",
   "metadata": {},
   "source": [
    "### Baseline Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'baseline_model_linear_regression'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f1fa",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'baseline_model_random_Forest'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28784bd5",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'baseline_model_XGB'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1aade1",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ori = df_train.copy(deep=True)\n",
    "df_test_ori = df_test.copy(deep=True)\n",
    "\n",
    "print(f'df_train = {df_train.shape}')\n",
    "print(f'df_test = {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train_ori.copy(deep=True)\n",
    "df_test=df_test_ori.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96536cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5d856",
   "metadata": {},
   "source": [
    "karena nanti we will using Linear regression too (plan : Linear Regression, Random Forest, XGBoost)\n",
    "we need to do scaling on the data <br>\n",
    "but scaling is only for the Linear Regression Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0edfe",
   "metadata": {},
   "source": [
    "### combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined_features(dfnya):\n",
    "\n",
    "    #custom feature ini dibuat as simple as grouping some feature that have similarity on their characteristics on supporting the house price\n",
    "    #you can find the process of the grouping in supportind document \"CategoricalEncodingnyaPakaiApa.xlsx\"\n",
    "    \n",
    "    dfnya['new_qualities'] = \tdfnya['num_overallqual'] + dfnya['txt_exterqual'] + dfnya['txt_bsmtqual'] + dfnya['txt_heatingqc'] + dfnya['num_lowqualfinsf'] + dfnya['num_halfbath'] + dfnya['num_kitchenabvgr'] + dfnya['txt_kitchenqual'] + dfnya['txt_fireplacequ'] + dfnya['txt_garagequal'] + dfnya['txt_poolqc'] + dfnya['txt_fence']\n",
    "    dfnya['new_condition'] = \tdfnya['txt_condition1'] + dfnya['txt_condition2'] + dfnya['num_overallcond'] + dfnya['txt_extercond'] + dfnya['txt_bsmtcond'] + dfnya['txt_heatingqc'] + dfnya['txt_centralair_Y'] + dfnya['num_2ndflrsf'] + dfnya['txt_garagecond'] + dfnya['txt_salecondition']\n",
    "    dfnya['new_square'] = \tdfnya['num_lotarea'] + dfnya['num_masvnrarea'] + dfnya['num_bsmtfinsf1'] + dfnya['num_bsmtfinsf2'] + dfnya['num_bsmtunfsf'] + dfnya['num_totalbsmtsf'] + dfnya['num_1stflrsf'] + dfnya['num_2ndflrsf'] + dfnya['num_lowqualfinsf'] + dfnya['num_grlivarea'] + dfnya['num_garagecars'] + dfnya['num_garagearea'] + dfnya['num_wooddecksf'] + dfnya['num_openporchsf'] + dfnya['num_enclosedporch'] + dfnya['num_3ssnporch'] + dfnya['num_screenporch'] + dfnya['num_poolarea']\n",
    "    dfnya['new_counts'] = \tdfnya['num_totalbsmtsf'] + dfnya['num_bsmtfullbath'] + dfnya['num_bsmthalfbath'] + dfnya['num_fullbath'] + dfnya['num_bedroomabvgr'] + dfnya['num_totrmsabvgrd'] + dfnya['num_fireplaces'] + dfnya['num_garagecars']\n",
    "    dfnya['new_types'] = \tdfnya['txt_mssubclass'] + (dfnya['txt_street_Grvl']*1)+ (dfnya['txt_street_Pave']*2)+(dfnya['txt_alley_NA'] *0) + (dfnya['txt_alley_Grvl'] *1) + (dfnya['txt_alley_Pave'] *2) + dfnya['txt_utilities'] + dfnya['txt_bldgtype'] + dfnya['txt_housestyle'] + dfnya['txt_roofstyle'] + dfnya['txt_masvnrtype'] + dfnya['txt_foundation'] + dfnya['txt_bsmtfintype1'] + dfnya['txt_bsmtfintype2'] + dfnya['txt_heating'] + dfnya['txt_functional'] + dfnya['txt_saletype']\n",
    "    dfnya['new_interiorexterior'] = \tdfnya['num_overallqual'] + dfnya['txt_roofstyle'] + dfnya['txt_roofmatl'] + dfnya['txt_exterior1st'] + dfnya['txt_exterior2nd'] + dfnya['txt_masvnrtype'] + dfnya['txt_bsmtfintype1'] + dfnya['num_bsmtfinsf1'] + dfnya['txt_bsmtfintype2'] + dfnya['num_bsmtfinsf2'] + dfnya['num_bsmtunfsf'] + dfnya['num_lowqualfinsf'] + dfnya['txt_garagefinish']\n",
    "    dfnya['new_neighbour'] = \tdfnya['txt_mssubclass'] + dfnya['txt_mszoning'] + dfnya['num_lotfrontage'] + (dfnya['txt_street_Grvl']*1)+ (dfnya['txt_street_Pave']*2) + (dfnya['txt_alley_NA'] *0) + (dfnya['txt_alley_Grvl'] *1) + (dfnya['txt_alley_Pave'] *2)  + dfnya['txt_landcontour'] + (dfnya['txt_landslope_Gtl'] *1) + (dfnya['txt_landslope_Mod'] *2) + (dfnya['txt_landslope_Sev'] *3)  + dfnya['txt_neighborhood'] + dfnya['txt_bsmtexposure'] + dfnya['txt_garagetype'] + (dfnya['txt_paveddrive_N'] *1) + (dfnya['txt_paveddrive_P'] *2) + (dfnya['txt_paveddrive_Y'] *3)  + dfnya['txt_fence']\n",
    "    dfnya['new_facilities'] = \tdfnya['txt_utilities'] + dfnya['txt_heating'] + dfnya['txt_electrical'] + dfnya['num_fireplaces'] + dfnya['txt_miscfeature'] + dfnya['num_miscval']\n",
    "    dfnya['new_shapes'] = \tdfnya['txt_lotshape'] + dfnya['txt_lotconfig'] + dfnya['txt_housestyle'] + dfnya['txt_bsmtexposure']\n",
    "    dfnya['new_time'] = \t((dfnya['num_yrsold']- ((dfnya['num_yearbuilt'] + dfnya['num_yearremodadd'])/2))+(dfnya['num_yrsold']- dfnya['num_garageyrblt']))/2\n",
    "    return dfnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = add_combined_features(df_train)\n",
    "df_test = add_combined_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_corr = df_train.corr(numeric_only=True)\n",
    "# show_corrMap(df_train_corr,f'./output/{sekarang}_df_train_corr.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efdea5",
   "metadata": {},
   "source": [
    "### drop feature yang correlation lemah <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_threshold = 0.05 # correlation threshold\n",
    "selected_features_prep=df_train_corr['num_saleprice']\n",
    "print(f'sebelum dipilih=\\n{selected_features_prep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selected_features_prep[abs(selected_features_prep) > selection_threshold]\n",
    "print('')\n",
    "print(f'selected_featres=\\n{selected_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names = selected_features.index.to_list()\n",
    "print(selected_feature_names)\n",
    "df_train=df_train[selected_feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4593e",
   "metadata": {},
   "source": [
    "### remove features with high correlation betwen features (>0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "target_column = 'num_saleprice' \n",
    "df_train, removed_features = remove_highly_correlated_features(df_train, target_column, threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc33e90",
   "metadata": {},
   "source": [
    "### remove features with high VIF Score > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44745f22",
   "metadata": {},
   "source": [
    "-- I disabled automatic VIF since it making model worse, it removing some important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, removed_features, VIF_result = calculate_vif_v2(df_train,'num_saleprice', 7.5)\n",
    "# print(removed_features)\n",
    "# print(VIF_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(VIF_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9050df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns\n",
    "df_test=df_test[df_train.columns]\n",
    "\n",
    "print(f'df_train = {df_train.shape}')\n",
    "print(f'df_test = {df_test.shape}')\n",
    "\n",
    "X_train = df_train.drop(columns=['num_saleprice'])\n",
    "y_train = df_train['num_saleprice']\n",
    "X_test = df_test.drop(columns=['num_saleprice'])\n",
    "y_test = df_test['num_saleprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d6fe4",
   "metadata": {},
   "source": [
    "## Modelling without Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f49edd",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abb37c",
   "metadata": {},
   "source": [
    "#### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b836c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)  # Add column names\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)  # Add column names\n",
    "\n",
    "df_train_scaled = pd.concat([X_train_scaled_df, y_train.reset_index(drop=True)], axis=1)\n",
    "df_test_scaled = pd.concat([X_test_scaled_df, y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "scaler_name = 'scaler'\n",
    "\n",
    "scaler_file_name = f'{sekarang}_{scaler_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_df_train_scaled.csv'\n",
    "df_test_filename= f'{sekarang}_df_test_scaled.csv'\n",
    "\n",
    "save_model(scaler, scaler_file_name)\n",
    "df_train_scaled.to_csv(df_train_filename)\n",
    "df_test_scaled.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "X_train_scaled = df_train_scaled.drop(columns=['num_saleprice'])\n",
    "y_train_scaled = df_train_scaled['num_saleprice']\n",
    "X_test_scaled = df_test_scaled.drop(columns=['num_saleprice'])\n",
    "y_test_scaled = df_test_scaled['num_saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Linear Regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3831eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_scaled, y_pred))\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "mape = calculate_mape(y_test_scaled,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'feauterEng_model_linear_regression'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebad957",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c52474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'feauterEng_model_random_Forest'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ee8ce",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f237ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'feauterEng_model_XGB'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "print(results_df[['Model','RMSE','MAE','MAPE','R2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4312ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88e1b8",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241b30e",
   "metadata": {},
   "source": [
    "### Tuning RandomSearch Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Custom RMSE scorer ---\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "# --- Random Forest hyperparameter space ---\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 2),\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# --- Initialize model ---\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# --- RandomizedSearchCV ---\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Fit the model ---\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# --- Best model, parameters, and CV score ---\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_  # Convert from negative RMSE\n",
    "\n",
    "# --- Predict ---\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Metrics ---\n",
    "rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "\n",
    "# --- Save outputs ---\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'tuned_RndSrch_model_RF'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename = f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename = f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(best_model, model_file_name)\n",
    "df_train.to_csv(df_train_filename, index=False)\n",
    "df_test.to_csv(df_test_filename, index=False)\n",
    "\n",
    "# --- Log results ---\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse_score,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\": ''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "# Show result summary\n",
    "print(results_df[['Model', 'RMSE', 'MAE', 'MAPE', 'R2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e517ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caab833",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63278bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d776df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361717e",
   "metadata": {},
   "source": [
    "### Tuning RandomSearch XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RMSE scorer\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': randint(200, 500),\n",
    "    'max_depth': randint(4, 7),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'subsample': uniform(0.6, 0.4),  # between 0.6 and 1.0\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 0.3),\n",
    "    'reg_alpha': uniform(0, 0.1),\n",
    "    'reg_lambda': uniform(0.5, 1.5),\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "xgb = XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model, params, and score\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_  # convert back from negative RMSE\n",
    "(best_model, best_params, best_score)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = calculate_mape(y_test,y_pred)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'tuned_RndSrch_model_XGB'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(best_model, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "# print(results_df[['Model','RMSE','MAE','MAPE','R2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537686c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021eba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d457f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1bdeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:,.4f}'.format):\n",
    "    print(results_df[['Model','RMSE', 'MAE','MAPE', 'R2']].sort_values(by=['R2'], ascending=[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e5c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a282638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c26ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "039dcef3",
   "metadata": {},
   "source": [
    "## Ensemble 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Random Forest needs scaling\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf', RandomForestRegressor(random_state=42)) \n",
    "])\n",
    "\n",
    "# XGB doesn't need scaling\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('xgb', XGBRegressor(random_state=42,\n",
    "        **{'colsample_bytree': 0.6183445065618531,\n",
    "        'gamma': 0.18624170532662737,\n",
    "        'learning_rate': 0.07948268164508285,\n",
    "        'max_depth': 5,\n",
    "        'n_estimators': 434,\n",
    "        'reg_alpha': 0.057964993447173846,\n",
    "        'reg_lambda': 1.0123448156848176,\n",
    "        'subsample': 0.8149053666856281})) \n",
    "])\n",
    "\n",
    "# Combine them in a stacking model\n",
    "stack = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf_model', rf_pipeline),\n",
    "        ('xgb_model', xgb_pipeline)\n",
    "    ],\n",
    "    final_estimator=LinearRegression(),  # meta-model\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_stack = stack.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_stack))\n",
    "mae = mean_absolute_error(y_test, y_pred_stack)\n",
    "r2 = r2_score(y_test, y_pred_stack)\n",
    "mape = calculate_mape(y_test,y_pred_stack)\n",
    "\n",
    "sekarang = f'./output/{get_now_string()}'\n",
    "model_name = 'ensembel_tuned_rf_xgb'\n",
    "model_file_name = f'{sekarang}_{model_name}.pkl'\n",
    "df_train_filename= f'{sekarang}_{model_name}_df_train.csv'\n",
    "df_test_filename= f'{sekarang}_{model_name}_df_test.csv'\n",
    "\n",
    "save_model(stack, model_file_name)\n",
    "df_train.to_csv(df_train_filename)\n",
    "df_test.to_csv(df_test_filename)\n",
    "\n",
    "\n",
    "\n",
    "resultnya = pd.DataFrame([{\n",
    "    \"Model\": model_name,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"MAPE\": mape,\n",
    "    \"R2\": r2,\n",
    "    \"Model File\": model_file_name,\n",
    "    \"df_train\": df_train_filename,\n",
    "    \"df_test\": df_test_filename,\n",
    "    \"Scaler File\":''\n",
    "}])\n",
    "\n",
    "results_df = pd.concat([results_df, resultnya], ignore_index=True)\n",
    "\n",
    "# print(results_df[['Model','RMSE','MAE','MAPE','R2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1566f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_rounded = results_df.copy()\n",
    "results_df_rounded[['RMSE', 'MAE', 'MAPE', 'R2']] = results_df_rounded[['RMSE', 'MAE', 'MAPE', 'R2']].round(4)\n",
    "results_df_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:,.4f}'.format):\n",
    "    print(results_df[['Model','RMSE', 'MAE','MAPE', 'R2']].sort_values(by=['R2'], ascending=[False]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datly)",
   "language": "python",
   "name": "datly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
